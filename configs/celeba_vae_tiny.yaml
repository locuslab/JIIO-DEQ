GPUS: (0,1)
LOG_DIR: 'log/'
DATA_DIR: ''
OUTPUT_DIR: 'output/'
WORKERS: 2
PRINT_FREQ: 100
COMMENT: 'Experiments_CelebA_tiny'

MODEL: 
  NAME: mdeq
  NUM_LAYERS: 10
  NUM_CLASSES: 8
  NUM_GROUPS: 8
  DROPOUT: 0.25
  F_THRES: 22
  B_THRES: 24
  WNORM: true
  DOWNSAMPLE_TIMES: 0
  EXPANSION_FACTOR: 5
  OUTPUT_NL: 'tanh'
  IMAGE_SIZE: 
    - 3
    - 64
    - 64
  EXTRA:
    FULL_STAGE:
      NUM_MODULES: 1
      NUM_BRANCHES: 2
      BLOCK: BASIC
      HEAD_CHANNELS:
      - 8
      - 16
      FINAL_CHANSIZE: 200
      NUM_BLOCKS:
      - 1
      - 1
      NUM_CHANNELS:
      - 24
      - 24
      FUSE_METHOD: SUM
      ENCODING_CHANNELS: 128
    FULL_BWD: false
CUDNN:
  BENCHMARK: true
  DETERMINISTIC: false
  ENABLED: true
DATASET:
  DATASET: 'celeba'
  DATA_FORMAT: 'jpg'
  ROOT: '/project_data/projects/swamig/data/'
  TEST_SET: 'val'
  TRAIN_SET: 'train'
  AUGMENT: False
TEST:
  BATCH_SIZE_PER_GPU: 36
  MODEL_FILE: ''
TRAIN:
  BATCH_SIZE_PER_GPU: 24
  BEGIN_EPOCH: 0
  END_EPOCH: 50
  RESUME: false
  LR_SCHEDULER: 'cosine'
  PRETRAIN_STEPS: 3000
  LR_FACTOR: 0.1
  LR_STEP:
  - 30
  - 60
  - 90
  OPTIMIZER: adam
  LR: 0.001
  WD: 0.0 #000025
  MOMENTUM: 0.9
  NESTEROV: true
  SHUFFLE: true
DEBUG:
  DEBUG: false
