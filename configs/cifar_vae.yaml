GPUS: (0,1)
LOG_DIR: 'log/'
DATA_DIR: ''
OUTPUT_DIR: 'output/'
WORKERS: 4
PRINT_FREQ: 100
COMMENT: 'Experiment_CIFAR_GEM'

MODEL: 
  NAME: mdeq
  NUM_LAYERS: 10
  NUM_GROUPS: 8
  DROPOUT: 0.3
  F_THRES: 18
  B_THRES: 20
  WNORM: true
  DOWNSAMPLE_TIMES: 0
  EXPANSION_FACTOR: 5
  OUTPUT_NL: 'tanh'
  IMAGE_SIZE: 
    - 3
    - 32
    - 32
  EXTRA:
    FULL_STAGE:
      NUM_MODULES: 1
      NUM_BRANCHES: 4
      BLOCK: BASIC
      HEAD_CHANNELS:
      - 14
      - 28
      - 56
      - 112
      FINAL_CHANSIZE: 1680
      NUM_BLOCKS:
      - 1
      - 1
      - 1
      - 1
      NUM_CHANNELS:
      - 32
      - 64
      - 128
      - 256
      FUSE_METHOD: SUM
      ENCODING_CHANNELS: 128
CUDNN:
  BENCHMARK: true
  DETERMINISTIC: false
  ENABLED: true
DATASET:
  DATASET: 'cifar10'
  DATA_FORMAT: 'jpg'
  ROOT: 'data/cifar10/'
  TEST_SET: 'val'
  TRAIN_SET: 'train'
  AUGMENT: false
TEST:
  BATCH_SIZE_PER_GPU: 64
  MODEL_FILE: ''
TRAIN:
  BATCH_SIZE_PER_GPU: 64
  BEGIN_EPOCH: 0
  END_EPOCH: 220
  RESUME: true
  LR_SCHEDULER: 'cosine'
  PRETRAIN_STEPS: 20000
  LR_FACTOR: 0.1
  LR_STEP:
  - 30
  - 60
  - 90
  OPTIMIZER: adam
  LR: 0.001
  WD: 0.0
  MOMENTUM: 0.9
  NESTEROV: true
  SHUFFLE: true
  # MODEL_FILE: 'output/cifar10/cifar_vae/scaled_kld_loss_numbatches_tanh_sqloss_copy/model_best.pth.tar'
DEBUG:
  DEBUG: false